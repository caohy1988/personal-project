{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# three levels of logic in name recognition\n",
    "1. filter single character\n",
    "2. filtert the name contain unalphabetic characters\n",
    "3. use Markov Chain model and Bigram to detect the valid name\n",
    "\n",
    "Ref:\n",
    "https://github.com/rrenaud/Gibberish-Detector\n",
    "\n",
    "Using Dataset from \n",
    "\n",
    "https://catalog.data.gov/dataset/baby-names-from-social-security-card-applications-national-level-data\n",
    "\n",
    "https://github.com/carltonnorthern/nickname-and-diminutive-names-lookup/blob/master/names.csv\n",
    "\n",
    "https://catalog.data.gov/dataset/names-from-census-2000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain model training part, don't need to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(line):\n",
    "    \"\"\" Return only the subset of chars from accepted_chars.\n",
    "    This helps keep the  model relatively small by ignoring punctuation, \n",
    "    infrequenty symbols, etc. \"\"\"\n",
    "    return [c.lower() for c in line if c.lower() in accepted_chars]\n",
    "\n",
    "def ngram(n, l):\n",
    "    \"\"\" Return all n grams from l after normalizing \"\"\"\n",
    "    filtered = normalize(l)\n",
    "    for start in range(0, len(filtered) - n + 1):\n",
    "        yield ''.join(filtered[start:start + n])\n",
    "    \n",
    "def avg_transition_prob(l, log_prob_mat):\n",
    "    \"\"\" Return the average transition prob from l through log_prob_mat. \"\"\"\n",
    "    log_prob = 0.0\n",
    "    transition_ct = 0\n",
    "    n = 2\n",
    "    for a, b in ngram(n, l):\n",
    "        log_prob += log_prob_mat[pos[a]][pos[b]]\n",
    "        transition_ct += 1\n",
    "    # The exponentiation translates from log probs to probs.\n",
    "    return math.exp(log_prob / (transition_ct or 1))\n",
    "\n",
    "def train():\n",
    "    \"\"\" Write a simple model as a pickle file \"\"\"\n",
    "    k = len(accepted_chars)\n",
    "    # Assume we have seen 10 of each character pair.  This acts as a kind of\n",
    "    # prior or smoothing factor.  This way, if we see a character transition\n",
    "    # live that we've never observed in the past, we won't assume the entire\n",
    "    # string has 0 probability.\n",
    "    counts = [[10 for i in xrange(k)] for i in xrange(k)]\n",
    "\n",
    "    # Count transitions from big text file, taken \n",
    "    # from http://norvig.com/spell-correct.html\n",
    "    for line in open('name.txt'):\n",
    "        for a, b in ngram(2, line):\n",
    "            counts[pos[a]][pos[b]] += 1\n",
    "\n",
    "    # Normalize the counts so that they become log probabilities.  \n",
    "    # We use log probabilities rather than straight probabilities to avoid\n",
    "    # numeric underflow issues with long texts.\n",
    "    # This contains a justification:\n",
    "    # http://squarecog.wordpress.com/2009/01/10/dealing-with-underflow-in-joint-probability-calculations/\n",
    "    for i, row in enumerate(counts):\n",
    "        s = float(sum(row))\n",
    "        for j in xrange(len(row)):\n",
    "            row[j] = math.log(row[j] / s)\n",
    "\n",
    "    # Find the probability of generating a few arbitrarily choosen good and\n",
    "    # bad phrases.\n",
    "    good_probs = [avg_transition_prob(l, counts) for l in open('good.txt')]\n",
    "    bad_probs = [avg_transition_prob(l, counts) for l in open('bad.txt')]\n",
    "\n",
    "    # Assert that we actually are capable of detecting the junk.\n",
    "    assert min(good_probs) > max(bad_probs)\n",
    "\n",
    "    # And pick a threshold halfway between the worst good and best bad inputs.\n",
    "    thresh = (min(good_probs) + max(bad_probs)) / 2\n",
    "    pickle.dump({'mat': counts, 'thresh': thresh}, open('gib_model.pki', 'wb'))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please run from here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_data = pickle.load(open('gib_model.pki', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accepted_chars = 'abcdefghijklmnopqrstuvwxyz '\n",
    "\n",
    "pos = dict([(char, idx) for idx, char in enumerate(accepted_chars)])\n",
    "\n",
    "\n",
    "def normalize(line):\n",
    "    \"\"\" Return only the subset of chars from accepted_chars.\n",
    "    This helps keep the  model relatively small by ignoring punctuation, \n",
    "    infrequenty symbols, etc. \"\"\"\n",
    "    return [c.lower() for c in line if c.lower() in accepted_chars]\n",
    "\n",
    "def ngram(n, l):\n",
    "    \"\"\" Return all n grams from l after normalizing \"\"\"\n",
    "    filtered = normalize(l)\n",
    "    for start in range(0, len(filtered) - n + 1):\n",
    "        yield ''.join(filtered[start:start + n])\n",
    "    \n",
    "def avg_transition_prob(l, log_prob_mat):\n",
    "    \"\"\" Return the average transition prob from l through log_prob_mat. \"\"\"\n",
    "    log_prob = 0.0\n",
    "    transition_ct = 0\n",
    "    for a, b in ngram(2, l):\n",
    "        log_prob += log_prob_mat[pos[a]][pos[b]]\n",
    "        transition_ct += 1\n",
    "    # The exponentiation translates from log probs to probs.\n",
    "    return math.exp(log_prob / (transition_ct or 1))\n",
    "\n",
    "def valid_name(string):\n",
    "    if not string:\n",
    "        return 0\n",
    "    if len(string) < 2:\n",
    "        return 0\n",
    "    if not string.isalpha():\n",
    "        return 0\n",
    "    string = string.lower()\n",
    "    \n",
    "    # using the pre-trained threshold to return 1 or 0\n",
    "    score = avg_transition_prob(string, model_data['mat'])\n",
    "    return score\n",
    "    if score >= model_data['thresh']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('hg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('fgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('gfsdgdfsg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('gsdfgsf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('fede')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('koli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('Jose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('Xinying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('Sami')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('Haiyuan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('Ankit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('asdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('qazcds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('sfffss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('aaasdc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('bcadc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('pdded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('ggghgh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('saaas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020720264894560258"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_name('eretytds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
